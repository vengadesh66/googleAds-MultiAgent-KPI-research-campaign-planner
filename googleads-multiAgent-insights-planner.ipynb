{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae6c086",
   "metadata": {},
   "source": [
    "# KPI Achievement Engine\n",
    "Multi-Agent ADK Architecture Notebook\n",
    "---\n",
    "This notebook is a cleaned, structured version of the `kpi_achievement_engine.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d52821",
   "metadata": {},
   "source": [
    "## Initialization & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ADK KPI ACHIEVEMENT ENGINE: Multi-Agent System for Google Ads Analysis\n",
    "#\n",
    "# This script implements the production-ready architecture using ADK principles\n",
    "# and Pydantic for robust A2A (Agent-to-Agent) communication.\n",
    "#\n",
    "# NOTE: If ADK libraries are not installed, the code uses Mock Classes to\n",
    "# successfully demonstrate the architecture and orchestration flow.\n",
    "# ============================================================================\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "import logging\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882e1a2",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " ADK and Google Cloud Imports/Fallbacks ---\n",
    "try:\n",
    "    # Standard ADK Imports\n",
    "    from google.adk.agents.llm_agent import Agent\n",
    "    from google.adk.tools import AgentTool\n",
    "    from google.adk.tools.bigquery import (\n",
    "        BigQueryToolset,\n",
    "        BigQueryCredentialsConfig\n",
    "    )\n",
    "    from google.adk.tools.bigquery.config import BigQueryToolConfig, WriteMode\n",
    "    from google.adk.tools.function_calling import FunctionDeclaration\n",
    "    import google.auth\n",
    "    print(\"ADK libraries successfully imported. Running with live ADK tools.\\n\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"WARNING: ADK or other required libraries not found. Using Mock ADK for successful demo run.\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5c705",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    " FALLBACK: Mock ADK Classes (SYNTAX CORRECTED) --- \n",
    "    class Agent:\n",
    "        def __init__(self, **kwargs): \n",
    "            self.name = kwargs.get('name', 'MockAgent')\n",
    "        def run(self, prompt):\n",
    "            # Simulation of agent output for local testing without ADK/BQ\n",
    "            if 'Insights_Agent' in self.name:\n",
    "                 return AnomalyReport(campaign_id=\"CAM_1234\", metric_name=\"ROAS\", deviation_value=\"-25% lower than target 4.5\", hypotheses=[\"Device type (Mobile/Desktop) bias.\", \"Geographic region underperformance (e.g., California/New York).\", \"Budget allocation imbalance.\"])\n",
    "            if 'Deep_Research_Agent' in self.name:\n",
    "                 return ResearchSummaryArtifact(root_cause=\"Mobile bidding strategy is set too low for high-value regions (US East Coast) leading to suppressed high-value conversions.\", supporting_data=\"SELECT AVG(ROAS) FROM ads_performance WHERE device='mobile' AND region IN ('NY', 'MA') -- shows 3.1 ROAS vs 5.5 for Desktop.\", actionable_summary=\"Confirmed root cause related to mobile bid strategy and geographic segmentation of conversion value.\")\n",
    "            if 'Planning_Agent' in self.name:\n",
    "                # The mock Planning Agent returns the final JSON string directly\n",
    "                return json.dumps({\n",
    "                    \"overall_strategy\": \"Immediate tactical shift to re-allocate mobile bids in underperforming high-value US regions, followed by a strategic ad copy and landing page refinement.\",\n",
    "                    \"estimated_timeline\": \"3 weeks\",\n",
    "                    \"quick_wins\": [\n",
    "                        {\"title\": \"Increase Mobile Bid Multiplier\", \"description\": \"Raise the mobile bid multiplier by 25% in high-gap regions (NY, MA, FL). Effort: 1 day.\", \"effort_level\": \"low\", \"expected_impact\": \"high\", \"implementation_steps\": [\"Apply bid adjustment in Google Ads UI.\", \"Monitor for 7 days.\"]}\n",
    "                    ],\n",
    "                    \"medium_effort\": [\n",
    "                        {\"title\": \"A/B Test New Mobile Ad Copy\", \"description\": \"Test new ad copy emphasizing mobile-specific value propositions. Effort: 1 week.\", \"effort_level\": \"medium\", \"expected_impact\": \"medium\", \"implementation_steps\": [\"Create 3 new responsive search ads.\", \"Set up 14-day A/B test.\"]}\n",
    "                    ],\n",
    "                    \"high_effort\": [\n",
    "                        {\"title\": \"Automate Smart Bidding Migration\", \"description\": \"Transition the campaign to 'Maximize Conversion Value with target ROAS' to better capture regional value differences. Effort: 2 weeks.\", \"effort_level\": \"high\", \"expected_impact\": \"transformational\", \"implementation_steps\": [\"Review conversion actions quality.\", \"Migrate bidding strategy and set ROAS target to 4.2.\"]}\n",
    "                    ],\n",
    "                })\n",
    "            return \"\"\n",
    "        \n",
    "    # Standard Python class definition for mock objects\n",
    "    class BigQueryToolset:\n",
    "        def __init__(self, **kwargs):\n",
    "            pass\n",
    "    class BigQueryCredentialsConfig:\n",
    "        def __init__(self, **kwargs):\n",
    "            pass\n",
    "    class BigQueryToolConfig:\n",
    "        def __init__(self, **kwargs):\n",
    "            pass\n",
    "    class WriteMode:\n",
    "        ALLOWED = \"ALLOWED\"\n",
    "    class FunctionDeclaration:\n",
    "        def __init__(self, **kwargs):\n",
    "            pass\n",
    "    \n",
    "    class MockAuth:\n",
    "        def default(self):\n",
    "            # Mocks the return structure of google.auth.default()\n",
    "            return (None, \"mock-project-id\")\n",
    "    # Provide a minimal mock 'google' object with an 'auth' attribute\n",
    "    import types\n",
    "    google = types.SimpleNamespace(auth=MockAuth())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA MODELS (A2A Contracts - Pydantic)\n",
    "# ============================================================================\n",
    "\n",
    "class AnomalyReport(BaseModel):\n",
    "    \"\"\"Structured report defining a specific KPI gap or anomaly (Insights Agent Output).\"\"\"\n",
    "    campaign_id: str = Field(..., description=\"The ID of the underperforming Google Ads Campaign.\")\n",
    "    metric_name: str = Field(..., description=\"The KPI metric (e.g., ROAS, Conversion Rate) showing the gap.\")\n",
    "    deviation_value: str = Field(..., description=\"The magnitude and direction of the deviation (e.g., '-1.2% lower').\")\n",
    "    hypotheses: List[str] = Field(..., description=\"Initial high-level guesses (e.g., device split, geo bias) for L2 research.\")\n",
    "\n",
    "class ResearchSummaryArtifact(BaseModel):\n",
    "    \"\"\"Structured artifact containing confirmed causal links (Deep Research Agent Output).\"\"\"\n",
    "    root_cause: str = Field(..., description=\"The confirmed primary causal factor for the performance gap.\")\n",
    "    supporting_data: str = Field(..., description=\"The raw data/SQL results that verify the root cause.\")\n",
    "    actionable_summary: str = Field(..., description=\"A summary of the technical findings ready for strategic planning.\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. BIGQUERY TOOLSET AND NL2SQL FUNCTION DECLARATION CONFIGURATION\n",
    "# ============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882f319",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85351cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    " USER CONFIGURATION REQUIRED (Edit for Live Data Access) ---\n",
    "PROJECT_ID = os.environ.get(\"GCP_PROJECT_ID\", \"your-gcp-project-id-HERE\") # <-- **EDIT THIS**\n",
    "DATASET_ID = \"google_ads_data\" # <-- **EDIT THIS if different**\n",
    "TABLE_NAME = \"ads_performance\" # <-- **EDIT THIS**\n",
    "FULLY_QUALIFIED_TABLE = f\"`{PROJECT_ID}.{DATASET_ID}.{TABLE_NAME}`\"\n",
    "\n",
    "# 3.1. Configure the ADK BigQuery Toolset\n",
    "bigquery_toolset = BigQueryToolset(\n",
    "    config=BigQueryToolConfig(\n",
    "        write_mode=WriteMode.ALLOWED,\n",
    "        application_name='kpi-ads-research-engine'\n",
    "    ),\n",
    "    credentials_config=BigQueryCredentialsConfig(\n",
    "        credentials=google.auth.default()[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3.2. Define the Precise NL2SQL Function Declaration\n",
    "execute_sql_declaration = FunctionDeclaration(\n",
    "    name=\"execute_bigquery_sql\",\n",
    "    description=f\"\"\"Tool used exclusively for deep quantitative analysis on Google Ads performance data in BigQuery. \n",
    "    The model must generate a SQL query on a single line that leverages analytical functions (e.g., joins, window functions) to test causality. \n",
    "    IMPORTANT: Always use the fully qualified dataset and table name: {FULLY_QUALIFIED_TABLE} to ensure execution succeeds.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The complete, single-line SQL query to execute against BigQuery.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. AGENT DEFINITIONS (ADK Agents)\n",
    "# ============================================================================\n",
    "\n",
    "# 4.1. Insights Agent (L1)\n",
    "insights_agent = Agent(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    name=\"Insights_Agent\",\n",
    "    description=\"Analyzes current Google Ads performance data in BigQuery and outputs a structured AnomalyReport.\",\n",
    "    instruction=f\"\"\"You are a KPI Monitoring Specialist. Your role is to calculate current performance metrics from the BigQuery data ({FULLY_QUALIFIED_TABLE}) and compare them to the user's target KPI.\n",
    "    1. **Prioritize Schema:** Use your BigQuery tools to understand the schema first, as an expert data analyst.\n",
    "    2. **Identify Gap:** Identify the top 3 dimensions (e.g., Campaign ID, Geo, Device) driving the largest negative deviation from the target.\n",
    "    3. **Output Strictly:** Output your findings **strictly** as a JSON object matching the Pydantic structure for AnomalyReport. \\n    4. **No Other Text:** Do NOT output any other text or reasoning.\n",
    "    \"\"\",\n",
    "    tools=[bigquery_toolset], \n",
    "    structured_output=AnomalyReport \n",
    ")\n",
    "\n",
    "# 4.2. Deep Research Agent (L2)\n",
    "research_agent = Agent(\n",
    "    model=\"gemini-2.5-pro\", \n",
    "    name=\"Deep_Research_Agent\",\n",
    "    description=\"Conducts deep, iterative data analysis to find the root cause of the performance gap.\",\n",
    "    instruction=f\"\"\"You are a Causal Data Research Specialist. Your input is an AnomalyReport (A2A Task Card) from the Insights Agent.\n",
    "    1. **Generate SQL:** Use the 'execute_bigquery_sql' tool and the hypotheses to generate and execute precise SQL queries to retrieve quantitative evidence.\n",
    "    2. **Hypothesis Test:** Test the hypotheses by generating complex BigQuery SQL (using window functions, joins, etc., and always using the fully qualified table name: {FULLY_QUALIFIED_TABLE}).\n",
    "    3. **Synthesize:** Compile the evidence (SQL results, causal links) into a comprehensive ResearchSummaryArtifact object for the Planning Agent.\n",
    "    \"\"\",\n",
    "    tools=[bigquery_toolset, execute_sql_declaration],\n",
    "    structured_output=ResearchSummaryArtifact \n",
    ")\n",
    "\n",
    "# 4.3. Planning Agent (L3)\n",
    "planning_agent = Agent(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    name=\"Planning_Agent\",\n",
    "    description=\"Translates technical findings into a prioritized, actionable business strategy.\",\n",
    "    instruction=f\"\"\"You are a Strategic Planning Expert. Your input is the Research Summary Artifact (data evidence) from the Deep Research Agent.\n",
    "    Your sole task is to synthesize the confirmed root cause and supporting data into an actionable strategy report.\n",
    "    The final output **must** be a single JSON object (no other text) containing three prioritized categories of recommendations:\n",
    "    1. **QUICK WINS** (Low Effort, Immediate Impact)\n",
    "    2. **MEDIUM EFFORT** (Moderate Effort, Significant Impact)\n",
    "    3. **HIGH EFFORT** (High Effort, Transformational Impact)\n",
    "    Each recommendation should include a title, detailed description, effort_level, expected_impact, and implementation_steps.\n",
    "    \"\"\",\n",
    "    tools=[], \n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. ADK ORCHESTRATOR AND EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_kpi_engine(kpi_target_prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"Executes the three-stage multi-agent workflow (Orchestrator).\"\"\"\n",
    "    \n",
    "    orchestration_trace = {\"steps\": {}, \"status\": \"success\"}\n",
    "\n",
    "    initial_prompt = f\"Assess current ROAS against a target of 4.5 and identify the top campaign holding back performance. Target timeframe: 30 days. Initial KPI goal: {kpi_target_prompt}\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3da4b",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    " STAGE 1: Insights Generation (L1) ---\n",
    "    logger.info(\"\\n--- STAGE 1: INSIGHTS AGENT RUNNING (KPI Monitoring) ---\")\n",
    "    logger.info(f\"Initial Prompt: {initial_prompt}\")\n",
    "    \n",
    "    try:\n",
    "        anomaly_report_object = insights_agent.run(initial_prompt)\n",
    "        # Support both Pydantic v2 (model_dump) and v1 (dict)\n",
    "        if hasattr(anomaly_report_object, \"model_dump\"):\n",
    "            anomaly_dict = anomaly_report_object.model_dump()\n",
    "        elif hasattr(anomaly_report_object, \"dict\"):\n",
    "            anomaly_dict = anomaly_report_object.dict()\n",
    "        else:\n",
    "            # If the agent returned a raw dict/string, normalize it\n",
    "            anomaly_dict = anomaly_report_object if isinstance(anomaly_report_object, dict) else {}\n",
    "        anomaly_data_json = json.dumps(anomaly_dict, indent=2)\n",
    "        \n",
    "        orchestration_trace[\"steps\"][\"insights\"] = {\n",
    "            \"data\": json.loads(anomaly_data_json),\n",
    "            \"status\": \"completed\",\n",
    "            \"next_input\": anomaly_data_json\n",
    "        }\n",
    "        logger.info(f\"L1 Output (AnomalyReport) successfully generated and validated:\\n{anomaly_data_json}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"STAGE 1 FAILED: {e}\")\n",
    "        orchestration_trace[\"status\"] = \"failed_insights\"\n",
    "        return orchestration_trace\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32a328",
   "metadata": {},
   "source": [
    "## Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7137d85",
   "metadata": {},
   "outputs": [],
   "source": [
    " STAGE 2: Deep Research (L2) ---\n",
    "    logger.info(\"\\n--- STAGE 2: DEEP RESEARCH AGENT RUNNING (Causal Analysis) ---\\n\")\n",
    "    \n",
    "    try:\n",
    "        research_artifact_object = research_agent.run(anomaly_data_json)\n",
    "        # Support both Pydantic v2 (model_dump) and v1 (dict)\n",
    "        if hasattr(research_artifact_object, \"model_dump\"):\n",
    "            research_dict = research_artifact_object.model_dump()\n",
    "        elif hasattr(research_artifact_object, \"dict\"):\n",
    "            research_dict = research_artifact_object.dict()\n",
    "        else:\n",
    "            research_dict = research_artifact_object if isinstance(research_artifact_object, dict) else {}\n",
    "        research_artifact_json = json.dumps(research_dict, indent=2)\n",
    "\n",
    "        orchestration_trace[\"steps\"][\"research\"] = {\n",
    "            \"data\": json.loads(research_artifact_json),\n",
    "            \"status\": \"completed\",\n",
    "            \"next_input\": research_artifact_json\n",
    "        }\n",
    "        logger.info(f\"L2 Output (ResearchSummaryArtifact) successfully generated:\\n{research_artifact_json}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"STAGE 2 FAILED (Check ADK/NL2SQL logs): {e}\")\n",
    "        orchestration_trace[\"status\"] = \"failed_research\"\n",
    "        return orchestration_trace\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb00fe",
   "metadata": {},
   "source": [
    "## Section 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac065830",
   "metadata": {},
   "outputs": [],
   "source": [
    " STAGE 3: Strategic Planning (L3) ---\n",
    "    logger.info(\"\\n--- STAGE 3: PLANNING AGENT RUNNING (Strategy Synthesis) ---\\n\")\n",
    "    \n",
    "    try:\n",
    "        final_plan_text = planning_agent.run(research_artifact_json)\n",
    "        final_plan = json.loads(final_plan_text)\n",
    "        \n",
    "        orchestration_trace[\"steps\"][\"planning\"] = {\n",
    "            \"data\": final_plan,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"STAGE 3 FAILED: {e}\")\n",
    "        orchestration_trace[\"status\"] = \"failed_planning\"\n",
    "        return orchestration_trace\n",
    "\n",
    "    logger.info(\"\\n--- FINAL STRATEGIC PLAN GENERATED ---\")\n",
    "    return orchestration_trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed4dc1",
   "metadata": {},
   "source": [
    "## Section 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c980c",
   "metadata": {},
   "outputs": [],
   "source": [
    " Main Execution Block ---\n",
    "\n",
    "# 1. Setup Authentication Check (best practice for ADK/GCP)\n",
    "try:\n",
    "    _, project_id = google.auth.default()\n",
    "    logger.info(f\"Authentication check passed for project: {project_id}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Authentication failed (this is OK for a mock-run demo): {e}\")\n",
    "    \n",
    "# 2. Execute the full engine with a sample KPI goal\n",
    "initial_kpi_target = \"I need to increase our quarter-over-quarter ROAS by 20% in the next 30 days for our US campaigns.\"\n",
    "\n",
    "print(\"\\n\" + \"*\" * 80)\n",
    "print(f\"STARTING KPI ACHIEVEMENT ENGINE FOR GOAL: {initial_kpi_target}\")\n",
    "print(\"*\" * 80)\n",
    "\n",
    "final_report_data = run_kpi_engine(initial_kpi_target)\n",
    "\n",
    "# 3. Print Final Summary (Structured Output)\n",
    "if final_report_data[\"status\"] == \"success\":\n",
    "    plan = final_report_data[\"steps\"][\"planning\"][\"data\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL ANALYSIS AND STRATEGY REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\n\\nOVERALL STRATEGY: {plan.get('overall_strategy', 'N/A')}\")\n",
    "    print(f\"ESTIMATED TIMELINE: {plan.get('estimated_timeline', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"\\n--- âš¡ Quick Wins ({len(plan.get('quick_wins', []))} Recommendations) ---\")\n",
    "    print(\"-\" * 30)\n",
    "    for rec in plan.get(\"quick_wins\", [])[:3]:\n",
    "        print(f\"  â€¢ **{rec.get('title', 'N/A')}**: {rec.get('description', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"--- ðŸ“ˆ Medium Effort ({len(plan.get('medium_effort', []))} Recommendations) ---\")\n",
    "    print(\"-\" * 30)\n",
    "    for rec in plan.get(\"medium_effort\", [])[:3]:\n",
    "        print(f\"  â€¢ **{rec.get('title', 'N/A')}**: {rec.get('description', 'N/A')}\")\n",
    "        \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"--- ðŸš€ High Effort ({len(plan.get('high_effort', []))} Recommendations) ---\")\n",
    "    print(\"-\" * 30)\n",
    "    for rec in plan.get(\"high_effort\", [])[:3]:\n",
    "        print(f\"  â€¢ **{rec.get('title', 'N/A')}**: {rec.get('description', 'N/A')}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\nAgent orchestration failed during stage: {final_report_data['status']}. Check logs above for details.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
